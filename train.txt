from keras.layers import Conv2D, UpSampling2D, MaxPooling2D
from keras.models import Sequential
from keras.callbacks import Callback
import random
import glob
import wandb
from wandb.keras import WandbCallback
import subprocess
import os
from PIL import Image
import numpy as np
from keras import backend as K
from keras.layers import LSTM, Dense, Dropout, Masking, Embedding,Input,Reshape,Lambda,Flatten

run = wandb.init(project='catz_test')
config = run.config

config.num_epochs = 3
config.batch_size = 16
config.img_dir = "images"
config.height = 96
config.width = 96

val_dir = 'catz/test'
train_dir = 'catz/train'

# automatically get the data if it doesn't exist
if not os.path.exists("catz"):
    print("Downloading catz dataset...")
    subprocess.check_output(
        "curl https://storage.googleapis.com/wandb/catz.tar.gz | tar xz", shell=True)


class ImageCallback(Callback):
    def on_epoch_end(self, epoch, logs):
        validation_X, validation_y = next(
            my_generator(15, val_dir))
        output = self.model.predict(validation_X)
        wandb.log({
            "input": [wandb.Image(np.concatenate(np.split(c, 5, axis=2), axis=1)) for c in validation_X],
            "output": [wandb.Image(np.concatenate([validation_y[i], o], axis=1)) for i, o in enumerate(output)]
        }, commit=False)

def embeded_weights(batch_size,img_dir):
    cat_dirs = glob.glob(img_dir + "/*")
    counter = 0
   
    input_images = np.zeros(
        (batch_size, config.width, config.height, 3 * 5))
    output_images = np.zeros((batch_size, config.width, config.height, 3))
    random.shuffle(cat_dirs)
    if ((counter+1)*batch_size >= len(cat_dirs)):
        counter = 0
    for i in range(batch_size):
        input_imgs = glob.glob(cat_dirs[counter + i] + "/cat_[0-5]*")
        imgs = [Image.open(img) for img in sorted(input_imgs)]
        input_images[i] = np.concatenate(imgs, axis=2)
        output_images[i] = np.array(Image.open(
            cat_dirs[counter + i] + "/cat_result.jpg"))
    return input_images
    
def my_generator(batch_size, img_dir):
    """A generator that returns 5 images plus a result image"""
    cat_dirs = glob.glob(img_dir + "/*")
    counter = 0
    while True:
        input_images = np.zeros(
            (batch_size, config.width, config.height, 3 * 5))
        output_images = np.zeros((batch_size, config.width, config.height, 3))
        random.shuffle(cat_dirs)
        if ((counter+1)*batch_size >= len(cat_dirs)):
            counter = 0
        for i in range(batch_size):
            input_imgs = glob.glob(cat_dirs[counter + i] + "/cat_[0-5]*")
            imgs = [Image.open(img) for img in sorted(input_imgs)]
            input_images[i] = np.concatenate(imgs, axis=2)
            output_images[i] = np.array(Image.open(
                cat_dirs[counter + i] + "/cat_result.jpg"))
        yield (input_images, output_images)
        counter += batch_size


model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', padding='same',
                 input_shape=(config.height, config.width, 5 * 3)))
model.add(MaxPooling2D(2, 2))
print(model.summary())

model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))
model.add(UpSampling2D((2, 2)))
model.add(Conv2D(3, (3, 3), activation='relu', padding='same'))
print(model.summary())

#model.add(Flatten())
#model.add(Dense(96*96*3, activation='relu'))
#model.add(Reshape((96,96,3)))
#print(model.summary())




#model.add(Reshape(input_shape=(1,96, 96, 3)))
#conv_to_LSTM_dims = (1, 96, 96, 3)
#model.add(Reshape(target_shape=conv_to_LSTM_dims))
#model.add(Lambda(lambda x: x[:, :, :, 12:15], input_shape=(config.height, config.width, 5 * 3)))


#print(model.summary())
#LSTM_to_conv_dims = (96,3,3)
#model.add(Reshape(target_shape=LSTM_to_conv_dims))

#print(model.summary())


#model.add(Conv2D(3, (3, 3), activation='relu', padding='same'))


# Embedding layer
num_words = 3 * 5
#input_images = embeded_weights(config.batch_size, train_dir)
"""model.add(
    Embedding(input_dim=96,
              output_dim=96,
              input_shape=(config.width, 5 * 3),
              trainable=True,
              mask_zero=True))"""
#model.add(Conv2D(32, (3, 3), activation='softmax', padding='same',
#                 input_shape=(config.height,config.width, 5 * 3)))

# Masking layer for pre-trained embeddings
#model.add(Masking(mask_value=0.0))

# Recurrent layer
'''
model.add(LSTM(1024,input_shape=(96, 15), return_sequences=False, 
               dropout=0.1, recurrent_dropout=0.1,go_backwards=True))
'''
'''model.add(Reshape((96,96*5*3),input_shape=(96, 96, 5 * 3)))
model.add(LSTM(1024, return_sequences=False, 
               dropout=0.1, recurrent_dropout=0.1,go_backwards=True))
               
# Fully connected layer
model.add(Dense(96*96*3, activation='relu'))
# Dropout for regularization
model.add(Dropout(0.25))
# Output layer
#model.add(Dense(num_words, activation='softmax'))
model.add(Reshape((96,96,3)))'''


def perceptual_distance(y_true, y_pred):
    print("y_true ::: {0}".format(y_true))
    print(y_pred)
    rmean = (y_true[:, :, :, 1] + y_pred[:, :, :, 1]) / 2
    r = y_true[:, :, :, 2] - y_pred[:, :, :, 2]
    g = y_true[:, :, :, 2] - y_pred[:, :, :, 2]
    b = y_true[:, :, :, 2] - y_pred[:, :, :, 2]

    return K.mean(K.sqrt((((128+rmean)*r*r)/256) + 1.4*g*g + (((256-rmean)*b*b)/256)))


#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[perceptual_distance])

model.fit_generator(my_generator(config.batch_size, train_dir),
                    steps_per_epoch=len(
                        glob.glob(train_dir + "/*")) // config.batch_size,
                    epochs=config.num_epochs, callbacks=[
    ImageCallback(), WandbCallback()],
       validation_steps=len(glob.glob(val_dir + "/*")) // config.batch_size,
        validation_data=my_generator(config.batch_size, val_dir))